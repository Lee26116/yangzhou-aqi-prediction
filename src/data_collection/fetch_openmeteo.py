# -*- coding: utf-8 -*-
"""
ä» Open-Meteo ä¸‹è½½å†å²å¤©æ°”æ•°æ®
å…è´¹ APIï¼Œæ— éœ€ Key
"""

import sys
import requests
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent))
from src.config import (
    RAW_DATA_DIR, DATA_COLLECTION_CONFIG, YANGZHOU_CONFIG
)

# API URL
ARCHIVE_API_URL = "https://archive-api.open-meteo.com/v1/archive"

# å¤©æ°”å‚æ•°
WEATHER_PARAMS = [
    "temperature_2m",
    "relative_humidity_2m",
    "wind_speed_10m",
    "wind_direction_10m",
    "surface_pressure",
    "precipitation",
    "cloud_cover",
    "weather_code",
    "dew_point_2m",
    "apparent_temperature",
    "rain",
    "snowfall",
    "visibility",
    "wind_gusts_10m",
    "soil_temperature_0cm",
    "boundary_layer_height",
    "uv_index"
]


def fetch_weather_for_location(lat, lon, start_date, end_date, location_name="æ‰¬å·"):
    """
    è·å–æŒ‡å®šä½ç½®çš„å†å²å¤©æ°”æ•°æ®

    Args:
        lat: çº¬åº¦
        lon: ç»åº¦
        start_date: å¼€å§‹æ—¥æœŸ YYYY-MM-DD
        end_date: ç»“æŸæ—¥æœŸ YYYY-MM-DD
        location_name: ä½ç½®åç§°

    Returns:
        DataFrame
    """
    print(f"\nğŸ“¥ ä¸‹è½½ {location_name} å†å²å¤©æ°”æ•°æ®...")
    print(f"   åæ ‡: ({lat}, {lon})")
    print(f"   æ—¶é—´èŒƒå›´: {start_date} ~ {end_date}")

    # Open-Meteo å•æ¬¡è¯·æ±‚æœ€å¤šæ”¯æŒ 366 å¤©ï¼Œéœ€è¦åˆ†æ‰¹ä¸‹è½½
    start = datetime.strptime(start_date, "%Y-%m-%d")
    end = datetime.strptime(end_date, "%Y-%m-%d")

    all_data = []

    current_start = start
    while current_start < end:
        # æ¯æ‰¹æœ€å¤š 365 å¤©
        current_end = min(current_start + timedelta(days=365), end)

        params = {
            "latitude": lat,
            "longitude": lon,
            "start_date": current_start.strftime("%Y-%m-%d"),
            "end_date": current_end.strftime("%Y-%m-%d"),
            "hourly": ",".join(WEATHER_PARAMS),
            "timezone": "Asia/Shanghai"
        }

        try:
            response = requests.get(ARCHIVE_API_URL, params=params, timeout=60)
            response.raise_for_status()
            data = response.json()

            if "hourly" in data:
                hourly = data["hourly"]
                df = pd.DataFrame(hourly)
                all_data.append(df)
                print(f"   âœ… {current_start.strftime('%Y-%m-%d')} ~ {current_end.strftime('%Y-%m-%d')}: {len(df)} æ¡è®°å½•")

        except Exception as e:
            print(f"   âŒ {current_start.strftime('%Y-%m-%d')} ~ {current_end.strftime('%Y-%m-%d')}: {e}")

        current_start = current_end + timedelta(days=1)

    if not all_data:
        print("   âŒ æ²¡æœ‰è·å–åˆ°æ•°æ®")
        return None

    # åˆå¹¶æ•°æ®
    combined_df = pd.concat(all_data, ignore_index=True)

    # è½¬æ¢æ—¶é—´åˆ—
    combined_df['datetime'] = pd.to_datetime(combined_df['time'])
    combined_df = combined_df.drop(columns=['time'])

    # å»é‡ï¼ˆå¯èƒ½æœ‰é‡å ï¼‰
    combined_df = combined_df.drop_duplicates(subset=['datetime']).reset_index(drop=True)

    # æ’åº
    combined_df = combined_df.sort_values('datetime').reset_index(drop=True)

    return combined_df


def download_yangzhou_weather():
    """ä¸‹è½½æ‰¬å·å†å²å¤©æ°”æ•°æ®"""
    start_date = DATA_COLLECTION_CONFIG["historical_start_date"]
    end_date = DATA_COLLECTION_CONFIG["historical_end_date"]

    df = fetch_weather_for_location(
        lat=YANGZHOU_CONFIG["latitude"],
        lon=YANGZHOU_CONFIG["longitude"],
        start_date=start_date,
        end_date=end_date,
        location_name="æ‰¬å·"
    )

    if df is not None:
        output_file = RAW_DATA_DIR / "yangzhou_weather_historical.csv"
        df.to_csv(output_file, index=False, encoding='utf-8')
        print(f"\nâœ… æ‰¬å·å†å²å¤©æ°”æ•°æ®å·²ä¿å­˜: {output_file}")
        print(f"   è®°å½•æ•°: {len(df)}")
        print(f"   æ—¶é—´èŒƒå›´: {df['datetime'].min()} ~ {df['datetime'].max()}")
        print(f"   åˆ—: {list(df.columns)}")

    return df


def download_upwind_cities_weather():
    """ä¸‹è½½ä¸Šé£å‘åŸå¸‚çš„å†å²å¤©æ°”æ•°æ®"""
    start_date = DATA_COLLECTION_CONFIG["historical_start_date"]
    end_date = DATA_COLLECTION_CONFIG["historical_end_date"]

    all_city_data = {}

    for city_name, coords in YANGZHOU_CONFIG["upwind_cities"].items():
        df = fetch_weather_for_location(
            lat=coords["lat"],
            lon=coords["lon"],
            start_date=start_date,
            end_date=end_date,
            location_name=city_name
        )

        if df is not None:
            # é‡å‘½ååˆ—ï¼Œæ·»åŠ åŸå¸‚å‰ç¼€
            rename_dict = {col: f"{city_name}_{col}" for col in df.columns if col != 'datetime'}
            df = df.rename(columns=rename_dict)
            all_city_data[city_name] = df

    if not all_city_data:
        print("âŒ æ²¡æœ‰è·å–åˆ°ä¸Šé£å‘åŸå¸‚å¤©æ°”æ•°æ®")
        return None

    # åˆå¹¶æ‰€æœ‰åŸå¸‚æ•°æ®
    merged_df = None
    for city_name, df in all_city_data.items():
        if merged_df is None:
            merged_df = df
        else:
            merged_df = merged_df.merge(df, on='datetime', how='outer')

    # æ’åº
    merged_df = merged_df.sort_values('datetime').reset_index(drop=True)

    # ä¿å­˜
    output_file = RAW_DATA_DIR / "upwind_cities_weather_historical.csv"
    merged_df.to_csv(output_file, index=False, encoding='utf-8')

    print(f"\nâœ… ä¸Šé£å‘åŸå¸‚å†å²å¤©æ°”æ•°æ®å·²ä¿å­˜: {output_file}")
    print(f"   è®°å½•æ•°: {len(merged_df)}")

    return merged_df


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("  Open-Meteo å†å²å¤©æ°”æ•°æ®ä¸‹è½½")
    print("=" * 60)

    # 1. ä¸‹è½½æ‰¬å·å¤©æ°”æ•°æ®
    download_yangzhou_weather()

    # 2. ä¸‹è½½ä¸Šé£å‘åŸå¸‚å¤©æ°”æ•°æ®
    download_upwind_cities_weather()


if __name__ == "__main__":
    main()
