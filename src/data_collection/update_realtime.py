# -*- coding: utf-8 -*-
"""
å¢é‡æ•°æ®æ›´æ–°æ¨¡å—
æ¯å°æ—¶ä» WAQI API å’Œ OpenMeteo API è·å–æœ€æ–°æ•°æ®
è¿½åŠ åˆ° yangzhou_merged.csv å¹¶é‡å»º DL ç‰¹å¾
"""

import sys
import json
import requests
import numpy as np
import pandas as pd
from datetime import datetime, timedelta, timezone
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent.parent))
from src.config import (
    PROCESSED_DATA_DIR, WAQI_TOKEN, YANGZHOU_CONFIG, CHINA_TIMEZONE
)

# WAQI åŸå¸‚åæ˜ å°„ï¼ˆä¸­æ–‡ â†’ æ‹¼éŸ³ï¼‰
CITY_PINYIN = {
    'æ‰¬å·': 'yangzhou',
    'å—äº¬': 'nanjing',
    'é•‡æ±Ÿ': 'zhenjiang',
    'æ³°å·': 'taizhou',
    'å—é€š': 'nantong',
}

# OpenMeteo Forecast APIï¼ˆç”¨äºè·å–æœ€è¿‘å‡ å°æ—¶çš„å¤©æ°”ï¼‰
FORECAST_API_URL = "https://api.open-meteo.com/v1/forecast"

WEATHER_PARAMS = [
    "temperature_2m", "relative_humidity_2m", "wind_speed_10m",
    "wind_direction_10m", "surface_pressure", "precipitation",
    "cloud_cover", "weather_code", "dew_point_2m", "apparent_temperature",
    "rain", "snowfall", "visibility", "wind_gusts_10m",
    "soil_temperature_0cm", "boundary_layer_height", "uv_index"
]

# ä¸­å›½ HJ 633-2012 IAQI æ–­ç‚¹è¡¨ï¼š(IAQI_low, IAQI_high, C_low, C_high)
# WAQI API è¿”å› IAQI å­æŒ‡æ•°ï¼Œéœ€è¦è½¬æ¢å›åŸå§‹æµ“åº¦ä»¥åŒ¹é… quotsoft.net è®­ç»ƒæ•°æ®
IAQI_BREAKPOINTS = {
    # CO: mg/mÂ³ (24h â†’ è¿‘ä¼¼1h)
    'co': [
        (0, 50, 0, 5), (50, 100, 5, 10), (100, 150, 10, 35),
        (150, 200, 35, 60), (200, 300, 60, 90), (300, 400, 90, 120),
        (400, 500, 120, 150),
    ],
    # NO2: Âµg/mÂ³ (1h)
    'no2': [
        (0, 50, 0, 100), (50, 100, 100, 200), (100, 150, 200, 700),
        (150, 200, 700, 1200), (200, 300, 1200, 2340), (300, 400, 2340, 3090),
        (400, 500, 3090, 3840),
    ],
    # SO2: Âµg/mÂ³ (1h)
    'so2': [
        (0, 50, 0, 150), (50, 100, 150, 500), (100, 150, 500, 650),
        (150, 200, 650, 800), (200, 300, 800, 1600), (300, 400, 1600, 2100),
        (400, 500, 2100, 2620),
    ],
    # O3: Âµg/mÂ³ (1h)
    'o3': [
        (0, 50, 0, 160), (50, 100, 160, 200), (100, 150, 200, 300),
        (150, 200, 300, 400), (200, 300, 400, 800), (300, 400, 800, 1000),
        (400, 500, 1000, 1200),
    ],
    # PM2.5: Âµg/mÂ³ (24h â†’ è¿‘ä¼¼1h)
    'pm25': [
        (0, 50, 0, 35), (50, 100, 35, 75), (100, 150, 75, 115),
        (150, 200, 115, 150), (200, 300, 150, 250), (300, 400, 250, 350),
        (400, 500, 350, 500),
    ],
    # PM10: Âµg/mÂ³ (24h â†’ è¿‘ä¼¼1h)
    'pm10': [
        (0, 50, 0, 50), (50, 100, 50, 150), (100, 150, 150, 250),
        (150, 200, 250, 350), (200, 300, 350, 420), (300, 400, 420, 500),
        (400, 500, 500, 600),
    ],
}


def iaqi_to_concentration(iaqi_value, pollutant):
    """
    å°† WAQI IAQI å­æŒ‡æ•°è½¬æ¢ä¸ºåŸå§‹æµ“åº¦å€¼

    WAQI API å¯¹ä¸­å›½ç«™ç‚¹è¿”å›çš„æ˜¯ HJ 633-2012 æ ‡å‡†çš„ IAQI å­æŒ‡æ•°ï¼Œ
    è€Œè®­ç»ƒæ•°æ® (quotsoft.net) ä½¿ç”¨åŸå§‹æµ“åº¦ (CO: mg/mÂ³, å…¶ä»–: Âµg/mÂ³)ã€‚
    """
    if iaqi_value is None or pollutant not in IAQI_BREAKPOINTS:
        return iaqi_value

    breakpoints = IAQI_BREAKPOINTS[pollutant]
    for iaqi_lo, iaqi_hi, c_lo, c_hi in breakpoints:
        if iaqi_lo <= iaqi_value <= iaqi_hi:
            ratio = (iaqi_value - iaqi_lo) / (iaqi_hi - iaqi_lo)
            return round(c_lo + ratio * (c_hi - c_lo), 2)

    # è¶…å‡ºèŒƒå›´ï¼Œç”¨æœ€é«˜æ–­ç‚¹å¤–æ¨
    if iaqi_value > 500:
        last = breakpoints[-1]
        return last[3]  # è¿”å›æœ€é«˜æµ“åº¦
    return iaqi_value


def fetch_waqi(city_pinyin):
    """ä» WAQI API è·å–åŸå¸‚å®æ—¶ AQI æ•°æ®ï¼Œå¹¶è½¬æ¢ä¸ºåŸå§‹æµ“åº¦"""
    url = f"https://api.waqi.info/feed/{city_pinyin}/?token={WAQI_TOKEN}"
    try:
        resp = requests.get(url, timeout=15)
        data = resp.json()
        if data.get('status') != 'ok':
            return None

        d = data['data']
        iaqi = d.get('iaqi', {})

        def v(key):
            val = iaqi.get(key)
            return val.get('v') if isinstance(val, dict) else val

        # è·å–åŸå§‹ IAQI å­æŒ‡æ•°
        raw_pm25 = v('pm25')
        raw_pm10 = v('pm10')
        raw_no2 = v('no2')
        raw_o3 = v('o3')
        raw_co = v('co')
        raw_so2 = v('so2')

        # è½¬æ¢ä¸ºåŸå§‹æµ“åº¦
        return {
            'aqi': d.get('aqi'),
            'pm25': iaqi_to_concentration(raw_pm25, 'pm25'),
            'pm10': iaqi_to_concentration(raw_pm10, 'pm10'),
            'no2': iaqi_to_concentration(raw_no2, 'no2'),
            'o3': iaqi_to_concentration(raw_o3, 'o3'),
            'co': iaqi_to_concentration(raw_co, 'co'),
            'so2': iaqi_to_concentration(raw_so2, 'so2'),
            'time_iso': d.get('time', {}).get('iso'),
        }
    except Exception as e:
        print(f"   âš ï¸ WAQI {city_pinyin} å¤±è´¥: {e}")
        return None


def fetch_openmeteo_recent(lat, lon, past_hours=6):
    """ä» OpenMeteo Forecast API è·å–æœ€è¿‘å‡ å°æ—¶çš„å¤©æ°”æ•°æ®"""
    params = {
        "latitude": lat,
        "longitude": lon,
        "hourly": ",".join(WEATHER_PARAMS),
        "past_hours": past_hours,
        "forecast_hours": 0,
        "timezone": "Asia/Shanghai",
    }
    try:
        resp = requests.get(FORECAST_API_URL, params=params, timeout=30)
        resp.raise_for_status()
        data = resp.json()

        if "hourly" not in data:
            return None

        hourly = data["hourly"]
        df = pd.DataFrame(hourly)
        df['datetime'] = pd.to_datetime(df['time'])
        df = df.drop(columns=['time'])
        return df

    except Exception as e:
        print(f"   âš ï¸ OpenMeteo å¤±è´¥: {e}")
        return None


def compute_time_features(dt):
    """è®¡ç®—æ—¶é—´ç‰¹å¾"""
    hour = dt.hour
    day = dt.day
    month = dt.month
    year = dt.year
    dow = dt.weekday()

    return {
        'hour': hour,
        'day': day,
        'month': month,
        'year': year,
        'day_of_week': dow,
        'day_of_year': dt.timetuple().tm_yday,
        'week_of_year': dt.isocalendar()[1],
        'is_weekend': dow >= 5,
        'is_holiday': False,
        'is_workday': dow < 5,
        'season': 1 if month in [3, 4, 5] else (2 if month in [6, 7, 8] else (3 if month in [9, 10, 11] else 4)),
        'is_harvest_season': month in [6, 7, 10, 11],
        'holiday_name': np.nan,
        'hour_sin': np.sin(2 * np.pi * hour / 24),
        'hour_cos': np.cos(2 * np.pi * hour / 24),
        'month_sin': np.sin(2 * np.pi * month / 12),
        'month_cos': np.cos(2 * np.pi * month / 12),
        'day_of_week_sin': np.sin(2 * np.pi * dow / 7),
        'day_of_week_cos': np.cos(2 * np.pi * dow / 7),
    }


def update_merged_data():
    """å¢é‡æ›´æ–° yangzhou_merged.csv"""
    merged_file = PROCESSED_DATA_DIR / "yangzhou_merged.csv"
    if not merged_file.exists():
        print("âŒ yangzhou_merged.csv ä¸å­˜åœ¨")
        return False

    # è¯»å–ç°æœ‰æ•°æ®
    df = pd.read_csv(merged_file)
    df['datetime'] = pd.to_datetime(df['datetime'])
    last_dt = df['datetime'].max()
    china_now = datetime.now(CHINA_TIMEZONE).replace(
        minute=0, second=0, microsecond=0, tzinfo=None
    )

    # è®¡ç®—éœ€è¦è¡¥å……çš„å°æ—¶æ•°
    hours_gap = int((china_now - last_dt).total_seconds() / 3600)
    if hours_gap <= 0:
        print(f"   æ•°æ®å·²æ˜¯æœ€æ–° (æœ€å: {last_dt})")
        return True

    print(f"   æœ€åæ•°æ®: {last_dt}")
    print(f"   å½“å‰æ—¶é—´: {china_now}")
    print(f"   éœ€è¡¥å……: {hours_gap} å°æ—¶")

    # è·å–æ‰¬å· AQI
    print("\nğŸ“¡ è·å–æ‰¬å·å®æ—¶ AQI...")
    yz_aqi = fetch_waqi('yangzhou')
    if yz_aqi:
        print(f"   AQI={yz_aqi['aqi']}, PM2.5={yz_aqi['pm25']}, PM10={yz_aqi['pm10']}")
    else:
        print("   âš ï¸ è·å–å¤±è´¥ï¼Œä½¿ç”¨ NaN")

    # è·å–ä¸Šé£å‘åŸå¸‚ AQI
    print("\nğŸ“¡ è·å–ä¸Šé£å‘åŸå¸‚ AQI...")
    upwind_aqi = {}
    for city_cn, city_py in CITY_PINYIN.items():
        if city_cn == 'æ‰¬å·':
            continue
        data = fetch_waqi(city_py)
        if data:
            upwind_aqi[city_cn] = data
            print(f"   {city_cn}: AQI={data['aqi']}")
        else:
            print(f"   {city_cn}: âš ï¸ å¤±è´¥")

    # è·å–å¤©æ°”æ•°æ®
    print(f"\nğŸŒ¤ï¸ è·å–æœ€è¿‘ {min(hours_gap + 2, 48)} å°æ—¶å¤©æ°”...")
    weather_df = fetch_openmeteo_recent(
        YANGZHOU_CONFIG['latitude'],
        YANGZHOU_CONFIG['longitude'],
        past_hours=min(hours_gap + 2, 48)
    )
    if weather_df is not None:
        print(f"   è·å–åˆ° {len(weather_df)} æ¡å¤©æ°”è®°å½•")
    else:
        print("   âš ï¸ å¤©æ°”æ•°æ®è·å–å¤±è´¥")

    # è·å–æœ€åå·²çŸ¥çš„ AQI å€¼ï¼ˆç”¨äºçº¿æ€§æ’å€¼å¡«å……ç¼ºå£ï¼‰
    last_known = {}
    for col in ['AQI', 'PM2.5', 'PM10', 'NO2', 'O3', 'CO', 'SO2']:
        vals = df[col].dropna()
        last_known[col] = vals.iloc[-1] if len(vals) > 0 else None

    # ä¸Šé£å‘åŸå¸‚æœ€åå·²çŸ¥å€¼
    for city_cn in ['å—äº¬', 'é•‡æ±Ÿ', 'æ³°å·', 'å—é€š']:
        for suffix in ['AQI', 'PM2.5', 'PM10']:
            col = f'{city_cn}_{suffix}'
            if col in df.columns:
                vals = df[col].dropna()
                last_known[col] = vals.iloc[-1] if len(vals) > 0 else None

    # æ„å»ºæ–°è¡Œ
    new_rows = []
    for h in range(1, hours_gap + 1):
        dt = last_dt + timedelta(hours=h)
        if dt > china_now:
            break

        row = {'datetime': dt}

        # AQI æ•°æ®ï¼šçº¿æ€§æ’å€¼ä»æœ€åå·²çŸ¥å€¼è¿‡æ¸¡åˆ°å½“å‰å®æ—¶å€¼
        # è¿™æ ·æ¨¡å‹çœ‹åˆ°çš„æ˜¯å¹³æ»‘å˜åŒ–è€Œéçªå˜
        ratio = h / hours_gap  # 0â†’1ï¼Œä»æ—§å€¼è¿‡æ¸¡åˆ°å½“å‰å€¼

        if yz_aqi:
            for col, waqi_key in [('AQI', 'aqi'), ('PM2.5', 'pm25'),
                                   ('PM10', 'pm10'), ('NO2', 'no2'),
                                   ('O3', 'o3'), ('CO', 'co'), ('SO2', 'so2')]:
                old_val = last_known.get(col)
                new_val = yz_aqi.get(waqi_key)
                if old_val is not None and new_val is not None:
                    row[col] = old_val * (1 - ratio) + new_val * ratio
                elif new_val is not None:
                    row[col] = new_val

            # ä¸Šé£å‘åŸå¸‚ï¼šåŒæ ·çº¿æ€§æ’å€¼
            for city_cn, data in upwind_aqi.items():
                for suffix, waqi_key in [('AQI', 'aqi'), ('PM2.5', 'pm25'), ('PM10', 'pm10')]:
                    col = f'{city_cn}_{suffix}'
                    old_val = last_known.get(col)
                    new_val = data.get(waqi_key)
                    if old_val is not None and new_val is not None:
                        row[col] = old_val * (1 - ratio) + new_val * ratio
                    elif new_val is not None:
                        row[col] = new_val

        # å¤©æ°”æ•°æ®
        if weather_df is not None:
            weather_row = weather_df[weather_df['datetime'] == dt]
            if len(weather_row) > 0:
                wr = weather_row.iloc[0]
                for col in WEATHER_PARAMS:
                    if col in wr.index:
                        row[col] = wr[col]

        # æ—¶é—´ç‰¹å¾
        row.update(compute_time_features(dt))

        new_rows.append(row)

    if not new_rows:
        print("   æ— æ–°æ•°æ®éœ€è¦æ·»åŠ ")
        return True

    # è¿½åŠ åˆ° DataFrame
    new_df = pd.DataFrame(new_rows)
    # ç¡®ä¿åˆ—å¯¹é½
    for col in df.columns:
        if col not in new_df.columns:
            new_df[col] = np.nan

    new_df = new_df[df.columns]  # ä¿æŒåˆ—é¡ºåº
    df = pd.concat([df, new_df], ignore_index=True)

    # å»é‡
    df = df.drop_duplicates(subset=['datetime'], keep='last').sort_values('datetime').reset_index(drop=True)

    # è®¡ç®— _24h æ»šåŠ¨å‡å€¼ï¼ˆå¯¹æœ€è¿‘çš„è¡Œï¼‰
    for col in ['PM2.5', 'PM10', 'CO', 'NO2', 'O3', 'SO2']:
        col_24h = f'{col}_24h'
        if col_24h in df.columns and col in df.columns:
            df[col_24h] = df[col].rolling(window=24, min_periods=1).mean()

    for city_cn in ['å—äº¬', 'é•‡æ±Ÿ', 'æ³°å·', 'å—é€š']:
        for pollutant in ['PM2.5', 'PM10']:
            col = f'{city_cn}_{pollutant}'
            col_24h = f'{city_cn}_{pollutant}_24h'
            if col_24h in df.columns and col in df.columns:
                df[col_24h] = df[col].rolling(window=24, min_periods=1).mean()

    # O3_8h å’Œ O3_8h_24h
    if 'O3' in df.columns:
        df['O3_8h'] = df['O3'].rolling(window=8, min_periods=1).mean()
        if 'O3_8h_24h' in df.columns:
            df['O3_8h_24h'] = df['O3_8h'].rolling(window=24, min_periods=1).mean()

    # ä¿å­˜
    df.to_csv(merged_file, index=False, encoding='utf-8')
    print(f"\nâœ… å·²è¿½åŠ  {len(new_rows)} è¡Œåˆ° {merged_file}")
    print(f"   æ•°æ®èŒƒå›´: {df['datetime'].min()} ~ {df['datetime'].max()}")
    print(f"   æ€»è¡Œæ•°: {len(df)}")

    return True


def rebuild_dl_features():
    """é‡å»º DL ç‰¹å¾æ–‡ä»¶"""
    print("\nğŸ”§ é‡å»º DL ç‰¹å¾...")
    try:
        from deep_learning.data.build_dl_features import main as build_features
        build_features()
        return True
    except Exception as e:
        print(f"   âš ï¸ DL ç‰¹å¾æ„å»ºå¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("  å¢é‡æ•°æ®æ›´æ–°")
    print("=" * 60)

    success = update_merged_data()
    if success:
        rebuild_dl_features()

    print("\nâœ… å¢é‡æ›´æ–°å®Œæˆ")


if __name__ == "__main__":
    main()
