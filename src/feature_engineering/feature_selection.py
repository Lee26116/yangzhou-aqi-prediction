# -*- coding: utf-8 -*-
"""
ç‰¹å¾ç­›é€‰æ¨¡å—
é€šè¿‡ç›¸å…³æ€§åˆ†æã€VIFã€ç‰¹å¾é‡è¦æ€§ç­‰æ–¹æ³•ç­›é€‰ç‰¹å¾
"""

import sys
import json
import numpy as np
import pandas as pd
from pathlib import Path
from sklearn.ensemble import RandomForestRegressor
from sklearn.feature_selection import mutual_info_regression

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent))
from src.config import FEATURES_DATA_DIR, DOCS_DIR


def calculate_correlation(df, target_col='AQI'):
    """
    è®¡ç®—ç‰¹å¾ä¸ç›®æ ‡å˜é‡çš„ç›¸å…³æ€§

    Args:
        df: DataFrame
        target_col: ç›®æ ‡å˜é‡åˆ—å

    Returns:
        DataFrame: ç›¸å…³æ€§ç»“æœ
    """
    print("ğŸ“Š è®¡ç®—ç‰¹å¾ç›¸å…³æ€§...")

    # åªé€‰æ‹©æ•°å€¼åˆ—
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()

    if target_col not in numeric_cols:
        print(f"   âŒ ç›®æ ‡å˜é‡ {target_col} ä¸æ˜¯æ•°å€¼ç±»å‹")
        return None

    # è®¡ç®—ç›¸å…³ç³»æ•°
    correlations = []
    for col in numeric_cols:
        if col == target_col:
            continue

        try:
            corr = df[col].corr(df[target_col])
            correlations.append({
                'feature': col,
                'correlation': corr,
                'abs_correlation': abs(corr)
            })
        except:
            continue

    corr_df = pd.DataFrame(correlations)
    corr_df = corr_df.sort_values('abs_correlation', ascending=False)

    return corr_df


def calculate_vif(df, features):
    """
    è®¡ç®—æ–¹å·®è†¨èƒ€å› å­ (VIF)

    Args:
        df: DataFrame
        features: ç‰¹å¾åˆ—è¡¨

    Returns:
        DataFrame: VIF ç»“æœ
    """
    print("ğŸ“Š è®¡ç®— VIF...")

    from statsmodels.stats.outliers_influence import variance_inflation_factor

    # å‡†å¤‡æ•°æ®
    X = df[features].dropna()

    if len(X) == 0:
        print("   âŒ æ•°æ®ä¸ºç©º")
        return None

    # è®¡ç®— VIF
    vif_data = []
    for i, col in enumerate(features):
        try:
            vif = variance_inflation_factor(X.values, i)
            vif_data.append({
                'feature': col,
                'VIF': vif
            })
        except Exception as e:
            vif_data.append({
                'feature': col,
                'VIF': np.nan
            })

    vif_df = pd.DataFrame(vif_data)
    vif_df = vif_df.sort_values('VIF', ascending=False)

    return vif_df


def calculate_feature_importance(df, target_col='AQI', n_estimators=100):
    """
    ä½¿ç”¨éšæœºæ£®æ—è®¡ç®—ç‰¹å¾é‡è¦æ€§

    Args:
        df: DataFrame
        target_col: ç›®æ ‡å˜é‡åˆ—å
        n_estimators: æ ‘çš„æ•°é‡

    Returns:
        DataFrame: ç‰¹å¾é‡è¦æ€§ç»“æœ
    """
    print("ğŸ“Š è®¡ç®—ç‰¹å¾é‡è¦æ€§ (éšæœºæ£®æ—)...")

    # å‡†å¤‡æ•°æ®
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    feature_cols = [c for c in numeric_cols if c != target_col]

    X = df[feature_cols].dropna()
    y = df.loc[X.index, target_col]

    # å¤„ç†æ— ç©·å€¼
    X = X.replace([np.inf, -np.inf], np.nan)
    valid_idx = ~X.isna().any(axis=1)
    X = X[valid_idx]
    y = y[valid_idx]

    if len(X) < 100:
        print(f"   âŒ æ ·æœ¬æ•°å¤ªå°‘: {len(X)}")
        return None

    # è®­ç»ƒéšæœºæ£®æ—
    rf = RandomForestRegressor(n_estimators=n_estimators, random_state=42, n_jobs=-1)
    rf.fit(X, y)

    # è·å–ç‰¹å¾é‡è¦æ€§
    importance_df = pd.DataFrame({
        'feature': feature_cols,
        'importance': rf.feature_importances_
    })
    importance_df = importance_df.sort_values('importance', ascending=False)

    return importance_df


def calculate_mutual_information(df, target_col='AQI'):
    """
    è®¡ç®—äº’ä¿¡æ¯

    Args:
        df: DataFrame
        target_col: ç›®æ ‡å˜é‡åˆ—å

    Returns:
        DataFrame: äº’ä¿¡æ¯ç»“æœ
    """
    print("ğŸ“Š è®¡ç®—äº’ä¿¡æ¯...")

    # å‡†å¤‡æ•°æ®
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    feature_cols = [c for c in numeric_cols if c != target_col]

    X = df[feature_cols].copy()
    y = df[target_col].copy()

    # å¤„ç†ç¼ºå¤±å€¼å’Œæ— ç©·å€¼
    X = X.replace([np.inf, -np.inf], np.nan)
    valid_idx = ~X.isna().any(axis=1) & ~y.isna()
    X = X[valid_idx].values
    y = y[valid_idx].values

    if len(X) < 100:
        print(f"   âŒ æ ·æœ¬æ•°å¤ªå°‘: {len(X)}")
        return None

    # è®¡ç®—äº’ä¿¡æ¯
    mi = mutual_info_regression(X, y, random_state=42)

    mi_df = pd.DataFrame({
        'feature': feature_cols,
        'mutual_info': mi
    })
    mi_df = mi_df.sort_values('mutual_info', ascending=False)

    return mi_df


def select_features(df, target_col='AQI',
                   min_correlation=0.1,
                   max_vif=10,
                   max_missing_rate=0.2,
                   top_n_importance=50):
    """
    ç»¼åˆç‰¹å¾ç­›é€‰

    Args:
        df: DataFrame
        target_col: ç›®æ ‡å˜é‡åˆ—å
        min_correlation: æœ€å°ç›¸å…³ç³»æ•°ç»å¯¹å€¼
        max_vif: æœ€å¤§ VIF å€¼
        max_missing_rate: æœ€å¤§ç¼ºå¤±ç‡
        top_n_importance: ä¿ç•™çš„ç‰¹å¾æ•°é‡

    Returns:
        tuple: (selected_features, excluded_features, selection_report)
    """
    print("\nğŸ” å¼€å§‹ç‰¹å¾ç­›é€‰...")

    # å‡†å¤‡ç»“æœ
    excluded_features = []
    selection_reasons = {}

    # è·å–æ‰€æœ‰æ•°å€¼ç‰¹å¾
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    feature_cols = [c for c in numeric_cols if c != target_col]

    print(f"   åˆå§‹ç‰¹å¾æ•°: {len(feature_cols)}")

    # 1. ç¼ºå¤±ç‡ç­›é€‰
    print("\n   [1/4] ç¼ºå¤±ç‡ç­›é€‰...")
    missing_rates = df[feature_cols].isna().mean()
    high_missing = missing_rates[missing_rates > max_missing_rate].index.tolist()

    for col in high_missing:
        excluded_features.append(col)
        selection_reasons[col] = f"ç¼ºå¤±ç‡è¿‡é«˜: {missing_rates[col]*100:.1f}% > {max_missing_rate*100:.0f}%"

    remaining_features = [c for c in feature_cols if c not in excluded_features]
    print(f"      æ’é™¤ {len(high_missing)} ä¸ªé«˜ç¼ºå¤±ç‰¹å¾ï¼Œå‰©ä½™ {len(remaining_features)} ä¸ª")

    # 2. ç›¸å…³æ€§ç­›é€‰
    print("\n   [2/4] ç›¸å…³æ€§ç­›é€‰...")
    corr_df = calculate_correlation(df, target_col)

    if corr_df is not None:
        low_corr = corr_df[corr_df['abs_correlation'] < min_correlation]['feature'].tolist()
        for col in low_corr:
            if col not in excluded_features:
                excluded_features.append(col)
                corr_val = corr_df[corr_df['feature'] == col]['correlation'].values[0]
                selection_reasons[col] = f"ç›¸å…³æ€§è¿‡ä½: {corr_val:.3f}"

        remaining_features = [c for c in feature_cols if c not in excluded_features]
        print(f"      æ’é™¤ {len(low_corr)} ä¸ªä½ç›¸å…³ç‰¹å¾ï¼Œå‰©ä½™ {len(remaining_features)} ä¸ª")

    # 3. ç‰¹å¾é‡è¦æ€§æ’åº
    print("\n   [3/4] ç‰¹å¾é‡è¦æ€§æ’åº...")
    importance_df = calculate_feature_importance(df[remaining_features + [target_col]], target_col)

    if importance_df is not None and len(importance_df) > top_n_importance:
        low_importance = importance_df.iloc[top_n_importance:]['feature'].tolist()
        for col in low_importance:
            if col not in excluded_features:
                excluded_features.append(col)
                imp_val = importance_df[importance_df['feature'] == col]['importance'].values[0]
                selection_reasons[col] = f"é‡è¦æ€§è¾ƒä½: {imp_val:.4f}"

        remaining_features = [c for c in remaining_features if c not in low_importance]
        print(f"      ä¿ç•™ Top {top_n_importance} é‡è¦ç‰¹å¾ï¼Œå‰©ä½™ {len(remaining_features)} ä¸ª")

    # 4. VIF ç­›é€‰ï¼ˆå¤„ç†å¤šé‡å…±çº¿æ€§ï¼‰
    print("\n   [4/4] VIF ç­›é€‰...")
    # VIF è®¡ç®—è¾ƒæ…¢ï¼Œåªå¯¹å‰©ä½™ç‰¹å¾è®¡ç®—
    if len(remaining_features) > 5:
        try:
            vif_df = calculate_vif(df[remaining_features].dropna(), remaining_features)

            if vif_df is not None:
                # è¿­ä»£åˆ é™¤é«˜ VIF ç‰¹å¾
                while True:
                    high_vif = vif_df[vif_df['VIF'] > max_vif]
                    if len(high_vif) == 0:
                        break

                    # åˆ é™¤ VIF æœ€é«˜çš„ç‰¹å¾
                    worst_feature = high_vif.iloc[0]['feature']
                    if worst_feature not in excluded_features:
                        excluded_features.append(worst_feature)
                        selection_reasons[worst_feature] = f"VIF è¿‡é«˜: {high_vif.iloc[0]['VIF']:.1f} > {max_vif}"

                    remaining_features = [c for c in remaining_features if c != worst_feature]

                    if len(remaining_features) < 5:
                        break

                    # é‡æ–°è®¡ç®— VIF
                    vif_df = calculate_vif(df[remaining_features].dropna(), remaining_features)
                    if vif_df is None:
                        break

                print(f"      VIF ç­›é€‰åå‰©ä½™ {len(remaining_features)} ä¸ªç‰¹å¾")
        except Exception as e:
            print(f"      âš ï¸ VIF è®¡ç®—å¤±è´¥: {e}")

    # æœ€ç»ˆç»“æœ
    selected_features = remaining_features

    print(f"\nâœ… ç‰¹å¾ç­›é€‰å®Œæˆ!")
    print(f"   æœ€ç»ˆä¿ç•™ç‰¹å¾: {len(selected_features)} ä¸ª")
    print(f"   æ’é™¤ç‰¹å¾: {len(excluded_features)} ä¸ª")

    # ç”Ÿæˆç­›é€‰æŠ¥å‘Š
    selection_report = {
        "initial_features": len(feature_cols),
        "selected_features": len(selected_features),
        "excluded_features": len(excluded_features),
        "parameters": {
            "min_correlation": min_correlation,
            "max_vif": max_vif,
            "max_missing_rate": max_missing_rate,
            "top_n_importance": top_n_importance
        }
    }

    return selected_features, excluded_features, selection_reasons, selection_report


def save_selection_results(selected_features, excluded_features, selection_reasons, corr_df, importance_df):
    """ä¿å­˜ç‰¹å¾ç­›é€‰ç»“æœ"""

    # 1. ä¿å­˜è¢«æ’é™¤çš„ç‰¹å¾
    excluded_file = DOCS_DIR / "feature_excluded.json"
    excluded_data = []
    for feat in excluded_features:
        excluded_data.append({
            "feature": feat,
            "reason": selection_reasons.get(feat, "æœªçŸ¥")
        })

    with open(excluded_file, 'w', encoding='utf-8') as f:
        json.dump(excluded_data, f, ensure_ascii=False, indent=2)

    print(f"ğŸ“„ æ’é™¤ç‰¹å¾åˆ—è¡¨å·²ä¿å­˜: {excluded_file}")

    # 2. ä¿å­˜é€‰ä¸­çš„ç‰¹å¾
    selected_file = DOCS_DIR / "feature_selected.json"

    selected_data = []
    for feat in selected_features:
        item = {"feature": feat}

        # æ·»åŠ ç›¸å…³æ€§
        if corr_df is not None:
            corr_row = corr_df[corr_df['feature'] == feat]
            if len(corr_row) > 0:
                item["correlation"] = round(corr_row['correlation'].values[0], 4)

        # æ·»åŠ é‡è¦æ€§
        if importance_df is not None:
            imp_row = importance_df[importance_df['feature'] == feat]
            if len(imp_row) > 0:
                item["importance"] = round(imp_row['importance'].values[0], 4)

        selected_data.append(item)

    # æŒ‰é‡è¦æ€§æ’åº
    selected_data.sort(key=lambda x: x.get('importance', 0), reverse=True)

    with open(selected_file, 'w', encoding='utf-8') as f:
        json.dump(selected_data, f, ensure_ascii=False, indent=2)

    print(f"ğŸ“„ é€‰ä¸­ç‰¹å¾åˆ—è¡¨å·²ä¿å­˜: {selected_file}")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("  ç‰¹å¾ç­›é€‰")
    print("=" * 60)

    # è¯»å–ç‰¹å¾æ•°æ®
    input_file = FEATURES_DATA_DIR / "yangzhou_features.csv"

    if not input_file.exists():
        print(f"âŒ ç‰¹å¾æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        print("   è¯·å…ˆè¿è¡Œ build_features.py")
        return

    df = pd.read_csv(input_file)
    print(f"ğŸ“– è¯»å–æ•°æ®: {len(df)} è¡Œ, {len(df.columns)} åˆ—")

    # è®¡ç®—ç›¸å…³æ€§
    corr_df = calculate_correlation(df)

    # è®¡ç®—ç‰¹å¾é‡è¦æ€§
    importance_df = calculate_feature_importance(df)

    # ç‰¹å¾ç­›é€‰
    selected, excluded, reasons, report = select_features(df)

    # ä¿å­˜ç»“æœ
    save_selection_results(selected, excluded, reasons, corr_df, importance_df)

    # ä¿å­˜ç­›é€‰åçš„æ•°æ®
    output_cols = ['datetime', 'AQI'] + selected
    output_cols = [c for c in output_cols if c in df.columns]

    df_selected = df[output_cols]
    output_file = FEATURES_DATA_DIR / "yangzhou_features_selected.csv"
    df_selected.to_csv(output_file, index=False, encoding='utf-8')

    print(f"\nâœ… ç­›é€‰åçš„ç‰¹å¾æ•°æ®å·²ä¿å­˜: {output_file}")
    print(f"   ä¿ç•™ç‰¹å¾: {len(selected)} ä¸ª")

    # æ‰“å° Top 20 ç‰¹å¾
    print("\nğŸ“Š Top 20 é‡è¦ç‰¹å¾:")
    if importance_df is not None:
        for i, row in importance_df.head(20).iterrows():
            print(f"   {i+1:2d}. {row['feature']:40s} {row['importance']:.4f}")

    return selected


if __name__ == "__main__":
    main()
