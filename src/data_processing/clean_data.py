# -*- coding: utf-8 -*-
"""
æ•°æ®æ¸…æ´—æ¨¡å—
å¤„ç†ç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼ã€æ—¶é—´å¯¹é½ç­‰
"""

import sys
import numpy as np
import pandas as pd
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent))
from src.config import RAW_DATA_DIR, PROCESSED_DATA_DIR


def clean_aqi_data(df):
    """
    æ¸…æ´— AQI æ•°æ®

    Args:
        df: åŸå§‹ AQI DataFrame

    Returns:
        æ¸…æ´—åçš„ DataFrame
    """
    print("ğŸ§¹ æ¸…æ´— AQI æ•°æ®...")

    df = df.copy()

    # ç¡®ä¿ datetime åˆ—æ˜¯ datetime ç±»å‹
    if 'datetime' in df.columns:
        df['datetime'] = pd.to_datetime(df['datetime'])

    # è®¾ç½® datetime ä¸ºç´¢å¼•
    if 'datetime' in df.columns:
        df = df.set_index('datetime')

    # å®šä¹‰æ•°å€¼åˆ—
    numeric_cols = ['AQI', 'PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3',
                    'PM2.5_24h', 'PM10_24h', 'SO2_24h', 'NO2_24h', 'CO_24h', 'O3_24h', 'O3_8h', 'O3_8h_24h']

    # è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
    for col in numeric_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')

    # å¼‚å¸¸å€¼å¤„ç†
    # AQI èŒƒå›´: 0-500
    if 'AQI' in df.columns:
        df.loc[df['AQI'] < 0, 'AQI'] = np.nan
        df.loc[df['AQI'] > 500, 'AQI'] = np.nan

    # PM2.5 èŒƒå›´: 0-1000
    if 'PM2.5' in df.columns:
        df.loc[df['PM2.5'] < 0, 'PM2.5'] = np.nan
        df.loc[df['PM2.5'] > 1000, 'PM2.5'] = np.nan

    # PM10 èŒƒå›´: 0-1000
    if 'PM10' in df.columns:
        df.loc[df['PM10'] < 0, 'PM10'] = np.nan
        df.loc[df['PM10'] > 1000, 'PM10'] = np.nan

    # æ£€æµ‹å¹¶å¤„ç†å¼‚å¸¸å€¼ (ä½¿ç”¨ IQR æ–¹æ³•)
    for col in ['AQI', 'PM2.5', 'PM10']:
        if col in df.columns:
            Q1 = df[col].quantile(0.25)
            Q3 = df[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 3 * IQR  # ä½¿ç”¨ 3 å€ IQRï¼Œæ›´å®½æ¾
            upper_bound = Q3 + 3 * IQR

            outliers = (df[col] < lower_bound) | (df[col] > upper_bound)
            n_outliers = outliers.sum()
            if n_outliers > 0:
                print(f"   {col}: å‘ç° {n_outliers} ä¸ªå¼‚å¸¸å€¼ï¼Œä½¿ç”¨æ’å€¼æ›¿æ¢")
                df.loc[outliers, col] = np.nan

    # å¤„ç†ç¼ºå¤±å€¼ - ä½¿ç”¨çº¿æ€§æ’å€¼
    df = df.interpolate(method='linear', limit=6)  # æœ€å¤šè¿ç»­æ’å€¼ 6 å°æ—¶

    # å‰å‘å¡«å……å‰©ä½™ç¼ºå¤±å€¼
    df = df.ffill(limit=3)

    # åå‘å¡«å……
    df = df.bfill(limit=3)

    # é‡ç½®ç´¢å¼•
    df = df.reset_index()

    # ç»Ÿè®¡ç¼ºå¤±æƒ…å†µ
    print(f"   æ¸…æ´—åç¼ºå¤±å€¼ç»Ÿè®¡:")
    for col in numeric_cols:
        if col in df.columns:
            missing = df[col].isna().sum()
            if missing > 0:
                print(f"      {col}: {missing} ({missing/len(df)*100:.2f}%)")

    return df


def clean_weather_data(df):
    """
    æ¸…æ´—å¤©æ°”æ•°æ®

    Args:
        df: åŸå§‹å¤©æ°” DataFrame

    Returns:
        æ¸…æ´—åçš„ DataFrame
    """
    print("ğŸ§¹ æ¸…æ´—å¤©æ°”æ•°æ®...")

    df = df.copy()

    # ç¡®ä¿ datetime åˆ—æ˜¯ datetime ç±»å‹
    if 'datetime' in df.columns:
        df['datetime'] = pd.to_datetime(df['datetime'])

    # è®¾ç½® datetime ä¸ºç´¢å¼•
    if 'datetime' in df.columns:
        df = df.set_index('datetime')

    # å®šä¹‰å„å˜é‡çš„åˆç†èŒƒå›´
    ranges = {
        'temperature_2m': (-40, 50),  # æ‘„æ°åº¦
        'relative_humidity_2m': (0, 100),  # ç™¾åˆ†æ¯”
        'wind_speed_10m': (0, 100),  # m/s
        'wind_direction_10m': (0, 360),  # åº¦
        'surface_pressure': (900, 1100),  # hPa
        'precipitation': (0, 200),  # mm
        'cloud_cover': (0, 100),  # ç™¾åˆ†æ¯”
        'boundary_layer_height': (0, 5000),  # ç±³
        'uv_index': (0, 15),  # UV æŒ‡æ•°
    }

    # å¤„ç†å¼‚å¸¸å€¼
    for col, (low, high) in ranges.items():
        if col in df.columns:
            outliers = (df[col] < low) | (df[col] > high)
            n_outliers = outliers.sum()
            if n_outliers > 0:
                print(f"   {col}: å‘ç° {n_outliers} ä¸ªè¶…èŒƒå›´å€¼ï¼Œè®¾ä¸º NaN")
                df.loc[outliers, col] = np.nan

    # å¤„ç†ç¼ºå¤±å€¼
    df = df.interpolate(method='linear', limit=6)
    df = df.ffill(limit=3)
    df = df.bfill(limit=3)

    # é‡ç½®ç´¢å¼•
    df = df.reset_index()

    return df


def align_time_series(dfs, freq='H'):
    """
    å¯¹é½å¤šä¸ªæ—¶é—´åºåˆ—æ•°æ®

    Args:
        dfs: DataFrame åˆ—è¡¨
        freq: é¢‘ç‡ï¼ŒH=å°æ—¶

    Returns:
        å¯¹é½åçš„ DataFrame åˆ—è¡¨
    """
    print("â° å¯¹é½æ—¶é—´åºåˆ—...")

    # æ‰¾åˆ°æ‰€æœ‰æ•°æ®çš„å…±åŒæ—¶é—´èŒƒå›´
    min_time = max(df['datetime'].min() for df in dfs if 'datetime' in df.columns)
    max_time = min(df['datetime'].max() for df in dfs if 'datetime' in df.columns)

    print(f"   å…±åŒæ—¶é—´èŒƒå›´: {min_time} ~ {max_time}")

    # åˆ›å»ºæ ‡å‡†æ—¶é—´ç´¢å¼•
    time_index = pd.date_range(start=min_time, end=max_time, freq=freq)

    aligned_dfs = []
    for df in dfs:
        if 'datetime' in df.columns:
            df = df.set_index('datetime')
            df = df.reindex(time_index)
            df = df.interpolate(method='linear', limit=3)
            df = df.reset_index().rename(columns={'index': 'datetime'})
        aligned_dfs.append(df)

    return aligned_dfs


def detect_data_quality_issues(df):
    """
    æ£€æµ‹æ•°æ®è´¨é‡é—®é¢˜

    Args:
        df: DataFrame

    Returns:
        é—®é¢˜æŠ¥å‘Š dict
    """
    df = df.copy()

    # ç¡®ä¿ datetime åˆ—æ˜¯ datetime ç±»å‹
    if 'datetime' in df.columns:
        df['datetime'] = pd.to_datetime(df['datetime'])

    report = {
        "total_rows": len(df),
        "columns": list(df.columns),
        "missing_values": {},
        "duplicates": 0,
        "time_gaps": [],
    }

    # ç¼ºå¤±å€¼ç»Ÿè®¡
    for col in df.columns:
        missing = df[col].isna().sum()
        if missing > 0:
            report["missing_values"][col] = {
                "count": int(missing),
                "percentage": round(missing / len(df) * 100, 2)
            }

    # é‡å¤è¡Œ
    if 'datetime' in df.columns:
        report["duplicates"] = int(df.duplicated(subset=['datetime']).sum())

        # æ£€æµ‹æ—¶é—´é—´éš”
        df_sorted = df.sort_values('datetime')
        time_diff = df_sorted['datetime'].diff()
        gaps = time_diff[time_diff > pd.Timedelta(hours=2)]

        for idx in gaps.index[:10]:  # åªè®°å½•å‰ 10 ä¸ª
            report["time_gaps"].append({
                "start": str(df_sorted.loc[idx - 1, 'datetime']),
                "end": str(df_sorted.loc[idx, 'datetime']),
                "duration_hours": time_diff.loc[idx].total_seconds() / 3600
            })

    return report


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("  æ•°æ®æ¸…æ´—")
    print("=" * 60)

    # è¯»å–åŸå§‹æ•°æ®
    aqi_file = RAW_DATA_DIR / "yangzhou_aqi_historical.csv"
    weather_file = RAW_DATA_DIR / "yangzhou_weather_historical.csv"

    if not aqi_file.exists():
        print(f"âŒ AQI æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {aqi_file}")
        print("   è¯·å…ˆè¿è¡Œ fetch_historical.py ä¸‹è½½æ•°æ®")
        return

    if not weather_file.exists():
        print(f"âŒ å¤©æ°”æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {weather_file}")
        print("   è¯·å…ˆè¿è¡Œ fetch_openmeteo.py ä¸‹è½½æ•°æ®")
        return

    # è¯»å–æ•°æ®
    print("\nğŸ“– è¯»å–åŸå§‹æ•°æ®...")
    aqi_df = pd.read_csv(aqi_file)
    weather_df = pd.read_csv(weather_file)

    print(f"   AQI æ•°æ®: {len(aqi_df)} è¡Œ")
    print(f"   å¤©æ°”æ•°æ®: {len(weather_df)} è¡Œ")

    # æ•°æ®è´¨é‡æ£€æµ‹
    print("\nğŸ” æ£€æµ‹æ•°æ®è´¨é‡é—®é¢˜...")
    aqi_report = detect_data_quality_issues(aqi_df)
    weather_report = detect_data_quality_issues(weather_df)

    # æ¸…æ´—æ•°æ®
    aqi_clean = clean_aqi_data(aqi_df)
    weather_clean = clean_weather_data(weather_df)

    # ä¿å­˜æ¸…æ´—åçš„æ•°æ®
    aqi_output = PROCESSED_DATA_DIR / "yangzhou_aqi_cleaned.csv"
    weather_output = PROCESSED_DATA_DIR / "yangzhou_weather_cleaned.csv"

    aqi_clean.to_csv(aqi_output, index=False, encoding='utf-8')
    weather_clean.to_csv(weather_output, index=False, encoding='utf-8')

    print(f"\nâœ… æ¸…æ´—åçš„æ•°æ®å·²ä¿å­˜:")
    print(f"   AQI: {aqi_output}")
    print(f"   å¤©æ°”: {weather_output}")

    # ä¿å­˜æ•°æ®è´¨é‡æŠ¥å‘Š
    import json
    report_file = PROCESSED_DATA_DIR / "data_quality_report.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump({
            "aqi": aqi_report,
            "weather": weather_report
        }, f, ensure_ascii=False, indent=2)

    print(f"   æ•°æ®è´¨é‡æŠ¥å‘Š: {report_file}")


if __name__ == "__main__":
    main()
