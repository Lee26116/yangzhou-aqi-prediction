# -*- coding: utf-8 -*-
"""
æ¨¡å‹è®­ç»ƒ v2 - ä½¿ç”¨æ–°ç‰¹å¾ï¼ˆä¸å«å…¶ä»–åŸå¸‚åŒæœŸAQIï¼‰
"""

import sys
import pickle
import numpy as np
import pandas as pd
from pathlib import Path
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from xgboost import XGBRegressor

sys.path.insert(0, str(Path(__file__).parent.parent.parent))
from src.config import FEATURES_DATA_DIR, MODELS_DIR


def load_data():
    """åŠ è½½ç‰¹å¾æ•°æ®"""
    input_file = FEATURES_DATA_DIR / "yangzhou_features_v2_selected.csv"

    if not input_file.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        return None, None, None

    df = pd.read_csv(input_file)
    df['datetime'] = pd.to_datetime(df['datetime'])
    df = df.sort_values('datetime').reset_index(drop=True)

    # åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡
    feature_cols = [c for c in df.columns if c not in ['datetime', 'AQI']]
    X = df[feature_cols]
    y = df['AQI']

    # å¤„ç†ç¼ºå¤±å€¼
    X = X.fillna(X.median())

    return X, y, feature_cols


def train_baselines(X, y):
    """è®­ç»ƒåŸºçº¿æ¨¡å‹"""
    print("\nğŸ“Š åŸºçº¿æ¨¡å‹è¯„ä¼°...")

    results = {}

    # 1. Naive: ç”¨1å°æ—¶å‰çš„AQIé¢„æµ‹
    if 'AQI_lag_1h' in X.columns:
        naive_pred = X['AQI_lag_1h'].values
        valid_idx = ~np.isnan(naive_pred)
        naive_mae = mean_absolute_error(y[valid_idx], naive_pred[valid_idx])
        naive_r2 = r2_score(y[valid_idx], naive_pred[valid_idx])
        results['Naive (lag 1h)'] = {'MAE': naive_mae, 'R2': naive_r2}
        print(f"   Naive (lag 1h): MAE={naive_mae:.2f}, RÂ²={naive_r2:.4f}")

    # 2. Moving Average: ç”¨è¿‡å»6å°æ—¶å‡å€¼é¢„æµ‹
    if 'AQI_rolling_mean_6h' in X.columns:
        ma_pred = X['AQI_rolling_mean_6h'].values
        valid_idx = ~np.isnan(ma_pred)
        ma_mae = mean_absolute_error(y[valid_idx], ma_pred[valid_idx])
        ma_r2 = r2_score(y[valid_idx], ma_pred[valid_idx])
        results['Moving Avg (6h)'] = {'MAE': ma_mae, 'R2': ma_r2}
        print(f"   Moving Avg (6h): MAE={ma_mae:.2f}, RÂ²={ma_r2:.4f}")

    return results


def train_xgboost(X, y, feature_cols):
    """è®­ç»ƒ XGBoost æ¨¡å‹"""
    print("\nğŸ¤– è®­ç»ƒ XGBoost æ¨¡å‹...")

    # æ—¶åºäº¤å‰éªŒè¯
    tscv = TimeSeriesSplit(n_splits=5)

    cv_results = {
        'MAE': [], 'RMSE': [], 'R2': [], 'MAPE': []
    }

    # XGBoost å‚æ•°
    params = {
        'n_estimators': 200,
        'max_depth': 6,
        'learning_rate': 0.1,
        'subsample': 0.8,
        'colsample_bytree': 0.8,
        'random_state': 42,
        'n_jobs': -1
    }

    print(f"   5-fold æ—¶åºäº¤å‰éªŒè¯...")

    for fold, (train_idx, test_idx) in enumerate(tscv.split(X)):
        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

        model = XGBRegressor(**params)
        model.fit(X_train, y_train, verbose=False)

        y_pred = model.predict(X_test)

        mae = mean_absolute_error(y_test, y_pred)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        r2 = r2_score(y_test, y_pred)
        mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100

        cv_results['MAE'].append(mae)
        cv_results['RMSE'].append(rmse)
        cv_results['R2'].append(r2)
        cv_results['MAPE'].append(mape)

        print(f"      Fold {fold+1}: MAE={mae:.2f}, RMSE={rmse:.2f}, RÂ²={r2:.4f}")

    # æ‰“å°å¹³å‡ç»“æœ
    print(f"\n   ğŸ“ˆ äº¤å‰éªŒè¯å¹³å‡ç»“æœ:")
    print(f"      MAE:  {np.mean(cv_results['MAE']):.2f} Â± {np.std(cv_results['MAE']):.2f}")
    print(f"      RMSE: {np.mean(cv_results['RMSE']):.2f} Â± {np.std(cv_results['RMSE']):.2f}")
    print(f"      RÂ²:   {np.mean(cv_results['R2']):.4f} Â± {np.std(cv_results['R2']):.4f}")
    print(f"      MAPE: {np.mean(cv_results['MAPE']):.2f}% Â± {np.std(cv_results['MAPE']):.2f}%")

    # è®­ç»ƒæœ€ç»ˆæ¨¡å‹ï¼ˆä½¿ç”¨å…¨éƒ¨æ•°æ®ï¼‰
    print(f"\n   è®­ç»ƒæœ€ç»ˆæ¨¡å‹...")
    final_model = XGBRegressor(**params)
    final_model.fit(X, y, verbose=False)

    return final_model, cv_results


def analyze_feature_importance(model, feature_cols):
    """åˆ†æç‰¹å¾é‡è¦æ€§"""
    print("\nğŸ“Š ç‰¹å¾é‡è¦æ€§åˆ†æ...")

    importance = model.feature_importances_
    imp_df = pd.DataFrame({
        'feature': feature_cols,
        'importance': importance
    }).sort_values('importance', ascending=False)

    print("   Top 15 é‡è¦ç‰¹å¾:")
    for i, row in imp_df.head(15).iterrows():
        pct = row['importance'] * 100
        bar = 'â–ˆ' * int(pct * 2)
        print(f"      {row['feature']:30} {pct:5.2f}% {bar}")

    return imp_df


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("  æ¨¡å‹è®­ç»ƒ v2 - ä¸ä½¿ç”¨å…¶ä»–åŸå¸‚åŒæœŸAQI")
    print("=" * 60)

    # åŠ è½½æ•°æ®
    X, y, feature_cols = load_data()
    if X is None:
        return

    print(f"\nğŸ“‚ æ•°æ®åŠ è½½å®Œæˆ:")
    print(f"   æ ·æœ¬æ•°: {len(X)}")
    print(f"   ç‰¹å¾æ•°: {len(feature_cols)}")

    # åŸºçº¿æ¨¡å‹
    baseline_results = train_baselines(X, y)

    # XGBoost
    model, cv_results = train_xgboost(X, y, feature_cols)

    # ç‰¹å¾é‡è¦æ€§
    imp_df = analyze_feature_importance(model, feature_cols)

    # ä¿å­˜æ¨¡å‹
    model_path = MODELS_DIR / "xgboost_model_v2.pkl"
    with open(model_path, 'wb') as f:
        pickle.dump(model, f)
    print(f"\nğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {model_path}")

    # ä¿å­˜ç‰¹å¾é‡è¦æ€§
    imp_path = MODELS_DIR / "feature_importance_v2.csv"
    imp_df.to_csv(imp_path, index=False)
    print(f"ğŸ’¾ ç‰¹å¾é‡è¦æ€§å·²ä¿å­˜: {imp_path}")

    # æ‰“å°å¯¹æ¯”
    print("\n" + "=" * 60)
    print("  æ¨¡å‹å¯¹æ¯”æ€»ç»“")
    print("=" * 60)

    print(f"\nåŸºçº¿æ¨¡å‹:")
    for name, metrics in baseline_results.items():
        print(f"   {name}: MAE={metrics['MAE']:.2f}, RÂ²={metrics['R2']:.4f}")

    print(f"\nXGBoost (v2, æ— å…¶ä»–åŸå¸‚AQI):")
    print(f"   MAE={np.mean(cv_results['MAE']):.2f}, RÂ²={np.mean(cv_results['R2']):.4f}")

    # è®¡ç®—ç›¸å¯¹åŸºçº¿çš„æå‡
    if 'Naive (lag 1h)' in baseline_results:
        baseline_mae = baseline_results['Naive (lag 1h)']['MAE']
        xgb_mae = np.mean(cv_results['MAE'])
        improvement = (baseline_mae - xgb_mae) / baseline_mae * 100
        print(f"\n   ç›¸å¯¹ Naive åŸºçº¿æå‡: {improvement:.1f}%")

    return model, cv_results, imp_df


if __name__ == "__main__":
    main()
